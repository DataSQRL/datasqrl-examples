# This is a docker-compose template for starting a DataSQRL compiled data pipeline
# This template uses the Apache Flink as the stream engine, Postgres as the database engine, and Vertx as the server engine.
# It assumes that:
# 1. You ran the `compile` command to compile your SQRL script (and API specification)
# 2. Are in the `build/deploy` directory which contains the deployment artifacts generated by the compiler
# 3. Have built the deployment artifacts for each pipeline engine
# Refer to the deployment documentation for more information:
# https://www.datasqrl.com/docs/reference/operations/deploy/overview/
version: "3.8"
volumes:
  redpanda-vol: null
services:
  database:
   image: yugabytedb/yugabyte:latest
   restart: always
   entrypoint: ["/bin/bash","-c"]
   command: 
    - |
      bin/yugabyted start --ysql_port 5432
      sleep 5
      bin/ysqlsh -h `hostname -i` -p 5432 -c '\x' -c "CREATE DATABASE datasqrl WITH COLOCATION = true;"
      bin/ysqlsh -h `hostname -i` -p 5432 -d "datasqrl" <<EOF
      \x
      CREATE ROLE postgres WITH LOGIN SUPERUSER PASSWORD 'postgres';
      EOF
      YSQL_PASSWORD="postgres" bin/ysqlsh -h `hostname -i` -p 5432 -d "datasqrl" -U "postgres" -f /home/yugabyte/docker-entrypoint-initdb.d/database-schema.sql
      tail -f /dev/null
   environment:
    - POSTGRES_USER=postgres
    - POSTGRES_PASSWORD=postgres
    - POSTGRES_DB=datasqrl
   ports:
    - '5432:5432'
    - '15433:15433'
    - '9042:9042'
   volumes:
    - ./database-schema.sql:/home/yugabyte/docker-entrypoint-initdb.d/database-schema.sql
  flink-jobmanager:
    image: flink:1.16.1-scala_2.12-java11
    restart: always
    ports:
      - "8081:8081"
    command: /bin/bash /exec/init-flink.sh jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager

  flink-taskmanager:
    image: flink:1.16.1-scala_2.12-java11
    restart: always
    depends_on:
      - flink-jobmanager
    command: /bin/bash /exec/init-flink.sh taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 1

  kafka:
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:9094
      # Address the broker advertises to clients that connect to the Kafka API.
      # Use the internal addresses to connect to the Redpanda brokers'
      # from inside the same Docker network.
      # Use the external addresses to connect to the Redpanda brokers'
      # from outside the Docker network.
      - --advertise-kafka-addr internal://kafka:9092,external://localhost:9094
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      # Address the broker advertises to clients that connect to the HTTP Proxy.
      - --advertise-pandaproxy-addr internal://kafka:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      # Redpanda brokers use the RPC API to communicate with each other internally.
      - --rpc-addr kafka:33145
      - --advertise-rpc-addr kafka:33145
      # Mode dev-container uses well-known configuration properties for development in containers.
      - --mode dev-container
      # enable logs for debugging.
      - --default-log-level=info
    image: docker.redpanda.com/redpandadata/redpanda:v23.3.3
    container_name: kafka
    volumes:
      - redpanda-vol:/var/lib/redpanda/data
    ports:
      - 18081:18081
      - 18082:18082
      - 9094:9094
      - 19644:9644

  kafka-setup:
    image: docker.io/bitnami/kafka:3.4.0-debian-11-r38
    volumes:
      - './create-topics.sh:/create-topics.sh'
    command: [ '/bin/bash', '/create-topics.sh' ]
    depends_on:
      - kafka

  server:
    image: eclipse-temurin:11
    restart: always
    command: java -jar vertx-server.jar
    depends_on:
      - database
      - kafka-setup
    ports:
      - "8888:8888"
    volumes:
      - ./server-model.json:/server-model.json
      - ./server-config.json:/server-config.json
      - ./vertx-server.jar:/vertx-server.jar

  flink-job-submitter:
    image: badouralix/curl-jq:alpine
    depends_on:
      - flink-jobmanager
      - database
      - kafka-setup
    volumes:
      - ./flink-job.jar:/flink-job.jar
      - ./submit-flink-job.sh:/submit-flink-job.sh
    entrypoint: /submit-flink-job.sh