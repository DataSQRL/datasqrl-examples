IMPORT tables.cdc_data;
IMPORT tables.compaction_tracker;
IMPORT udfs.read_partition_sizes;
IMPORT udfs.delete_deduplicated_data;

--
-- Part 1: Gather partitions to compact
--

_Partitions :=
SELECT *
FROM TABLE(read_partition_sizes('{{warehouse}}', '{{catalogType}}', '{{catalogName}}', '{{databaseName}}',
                                '{{tableName}}', '{{partitionCol}}'))
WHERE time_bucket <= FLOOR((CAST('${DEPLOYMENT_TIMESTAMP}' AS BIGINT) - {{bufferSeconds}}) / {{bucketSeconds}}) * {{bucketSeconds}};

_PartitionSizing :=
SELECT partition_id,
       SUM(CASE WHEN time_bucket = 0 THEN partition_size ELSE 0 END) AS base_size,
       SUM(CASE WHEN time_bucket > 0 THEN partition_size ELSE 0 END) AS new_size
FROM _Partitions
GROUP BY partition_id;

_PartitionSizing.total_size := base_size + new_size;
_PartitionSizing.new_rel_percentage := CAST(new_size AS DOUBLE) / GREATEST(total_size, 1) * 100;
_PartitionSizing.new_abs_percentage := CAST(new_size AS DOUBLE) / {{newDataNormalizer}} * 100;
_PartitionSizing.score := new_rel_percentage + new_abs_percentage;

_PartitionPriority :=
SELECT d.{{partitionCol}} AS partition_id,
    d.time_bucket,
    p.new_size,
    p.total_size,
    p.new_rel_percentage,
    p.new_abs_percentage,
    p.new_rel_percentage + p.new_abs_percentage AS score,
    ROW_NUMBER() OVER (ORDER BY (p.new_rel_percentage + p.new_abs_percentage) DESC) AS row_num,
    SUM (p.total_size) OVER (
      ORDER BY (p.new_rel_percentage + p.new_abs_percentage) DESC
      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_total_size
FROM CdcData d JOIN _PartitionSizing p ON d.{{partitionCol}} = p.partition_id;

_PartitionsToCompact :=
SELECT DISTINCT '{{tableName}}' AS table_name,
                '${DEPLOYMENT_ID}' AS job_id,
                partition_id,
                new_rel_percentage,
                new_abs_percentage,
                FLOOR((CAST('${DEPLOYMENT_TIMESTAMP}' AS BIGINT) - {{bufferSeconds}}) / {{bucketSeconds}}) * {{bucketSeconds}} AS max_time_bucket,
                'initialize' AS action,
                NOW() AS action_time
FROM _PartitionPriority
WHERE cumulative_total_size <= {{maxTotalPartitionSizeInBytes}}
   OR row_num <= 1;

INSERT INTO CompactionTracker SELECT * FROM _PartitionsToCompact;

NEXT_BATCH;

--
-- Part 2: Compact gathered partitions
--

_DataToCompact :=
SELECT DISTINCT table_name,
                job_id,
                partition_id,
                new_rel_percentage,
                new_abs_percentage,
                max_time_bucket
FROM CompactionTracker
WHERE LOWER(table_name) = LOWER('{{tableName}}')
  AND job_id = '${DEPLOYMENT_ID}'
  AND action = 'initialize'
  AND action_time > NOW() - INTERVAL '4' HOUR; -- last condition is for efficient pruning of iceberg read

_InputData :=
SELECT /*+ BROADCAST(c) */ d.*
FROM {{tableName}} AS d
        JOIN _DataToCompact AS c
ON d.{{partitionCol}} = c.partition_id AND d.time_bucket <= c.max_time_bucket;

_InputData.time_bucket := 0;

_DistInputData := DISTINCT _InputData ON {{partitionCol}} ORDER BY ts DESC;

INSERT OVERWRITE {{tableName}} SELECT * FROM _DistInputData;

_CompactionResult :=
SELECT table_name,
       job_id,
       partition_id,
       new_rel_percentage,
       new_abs_percentage,
       max_time_bucket,
       'overwrite' AS action,
       NOW() AS action_time
FROM _DataToCompact;

INSERT INTO CompactionTracker SELECT * FROM _CompactionResult;

NEXT_BATCH;

--
-- Part 3: Delete source partitions that were compacted
--

_DataToDelete :=
SELECT DISTINCT table_name,
                job_id,
                partition_id,
                new_rel_percentage,
                new_abs_percentage,
                max_time_bucket
FROM CompactionTracker
WHERE LOWER(table_name) = LOWER('{{tableName}}')
  AND job_id = '${DEPLOYMENT_ID}'
  AND action = 'overwrite'
  AND action_time > NOW() - INTERVAL '4' HOUR;

_DeleteFnResult :=
SELECT delete_deduplicated_data(
               '{{warehouse}}',
               '{{catalogType}}',
               '{{catalogName}}',
               '{{databaseName}}',
               MAX(table_name),
               '{{partitionCol}}',
               MAX(max_time_bucket),
               COLLECT(partition_id)) AS res
FROM _DataToDelete;

_DeleteResult :=
SELECT
    d.*,
    CASE WHEN fn.res = true THEN 'delete' ELSE 'delete_failed' END AS action,
        NOW() AS action_time
FROM _DataToDelete AS d
    CROSS JOIN (SELECT res FROM _DeleteFnResult LIMIT 1) AS fn;

INSERT INTO CompactionTracker SELECT * FROM _DeleteResult;
